# -Fine-Tuning-BERT-base-for-Sentiment-Analysis.
Google app store review are used to fine tune BERT-base for sentiment analysis

BERT stands for Bidirectional Encoder Representations from Transformers. It is state of the art NLP technique for a variety of applications such as Name Entity Recognition, Text classification, Question and Answering and many more. BERT was developed by Google Research team and made it public in October 2018. The backbone of BERTs amazing performance is Attention Heads which is borrowed from a previously developed transformer model. Attention Heads allows the model to understand the contextual information hidden inside the data and generates Embedding vectors accordingly.
